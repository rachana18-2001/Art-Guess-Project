{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Convolutional Neural Network to distinguish 88 different category of doodles - v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on 1000 images from each category and testing on 100 images from each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture of the CNN\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "# first conv layer\n",
    "classifier.add(Convolution2D(\n",
    "        input_shape=(28,28,1),\n",
    "        filters=32,\n",
    "        kernel_size=(3,3),\n",
    "        activation='relu',\n",
    "        kernel_initializer='uniform'))\n",
    "\n",
    "# second conv layer\n",
    "classifier.add(Convolution2D(\n",
    "        filters=32,\n",
    "        kernel_size=(1,1),\n",
    "        activation='relu',\n",
    "        kernel_initializer='uniform'))\n",
    "\n",
    "# max pooling layer\n",
    "classifier.add(MaxPooling2D(\n",
    "        pool_size=(2,2),\n",
    "        strides=(2,2)))\n",
    "\n",
    "# third conv layer\n",
    "classifier.add(Convolution2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3,3),\n",
    "        activation='relu',\n",
    "        kernel_initializer='uniform'))\n",
    "\n",
    "# max pooling layer\n",
    "classifier.add(MaxPooling2D(\n",
    "        pool_size=(2,2),\n",
    "        strides=(2,2)))\n",
    "\n",
    "# flattening for feeding the data to a fully connected artificial neural network\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# first hidden layer\n",
    "classifier.add(Dense(units=256, activation='relu', kernel_initializer='uniform'))\n",
    "classifier.add(Dropout(rate=0.5))\n",
    "\n",
    "# output layer\n",
    "classifier.add(Dense(units=88, activation='softmax', kernel_initializer='uniform'))\n",
    "\n",
    "# compiling the CNN\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87120 images belonging to 88 classes.\n",
      "Found 9680 images belonging to 88 classes.\n"
     ]
    }
   ],
   "source": [
    "# image preprocessing before feeding into the CNN\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_generator = ImageDataGenerator(rescale=1./255, rotation_range=0.05, validation_split=0.1)\n",
    "\n",
    "# training data set\n",
    "train_set = data_generator.flow_from_directory(\n",
    "        'dataset',\n",
    "        batch_size=64,\n",
    "        target_size=(28,28), color_mode='grayscale', subset='training')\n",
    "\n",
    "# testing/validation data set\n",
    "test_set = data_generator.flow_from_directory(\n",
    "        'dataset',\n",
    "        batch_size=64,\n",
    "        target_size=(28,28), color_mode='grayscale', subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mr_paul/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1362/1362 [==============================] - 188s 138ms/step - loss: 3.2949 - acc: 0.2134 - val_loss: 2.2453 - val_acc: 0.4552\n",
      "Epoch 2/10\n",
      "1362/1362 [==============================] - 106s 78ms/step - loss: 2.3572 - acc: 0.4088 - val_loss: 1.8817 - val_acc: 0.5454\n",
      "Epoch 3/10\n",
      "1362/1362 [==============================] - 103s 75ms/step - loss: 2.1411 - acc: 0.4608 - val_loss: 1.7298 - val_acc: 0.5741\n",
      "Epoch 4/10\n",
      "1362/1362 [==============================] - 103s 75ms/step - loss: 2.0267 - acc: 0.4865 - val_loss: 1.6437 - val_acc: 0.5971\n",
      "Epoch 5/10\n",
      "1362/1362 [==============================] - 103s 76ms/step - loss: 1.9444 - acc: 0.5077 - val_loss: 1.5754 - val_acc: 0.6055\n",
      "Epoch 6/10\n",
      "1362/1362 [==============================] - 105s 77ms/step - loss: 1.8745 - acc: 0.5225 - val_loss: 1.5214 - val_acc: 0.6244\n",
      "Epoch 7/10\n",
      "1362/1362 [==============================] - 104s 76ms/step - loss: 1.8239 - acc: 0.5347 - val_loss: 1.4835 - val_acc: 0.6242\n",
      "Epoch 8/10\n",
      "1362/1362 [==============================] - 103s 76ms/step - loss: 1.7736 - acc: 0.5448 - val_loss: 1.4611 - val_acc: 0.6368\n",
      "Epoch 9/10\n",
      "1362/1362 [==============================] - 103s 76ms/step - loss: 1.7259 - acc: 0.5577 - val_loss: 1.4342 - val_acc: 0.6424\n",
      "Epoch 10/10\n",
      "1362/1362 [==============================] - 103s 76ms/step - loss: 1.6956 - acc: 0.5634 - val_loss: 1.3996 - val_acc: 0.6442\n"
     ]
    }
   ],
   "source": [
    "# finally fitting the data and training the CNN\n",
    "history = classifier.fit_generator(\n",
    "        epochs=10,\n",
    "        initial_epoch=0,\n",
    "        generator=train_set,\n",
    "        steps_per_epoch=1362,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=152,\n",
    "        use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "1362/1362 [==============================] - 110s 81ms/step - loss: 1.6595 - acc: 0.5726 - val_loss: 1.3759 - val_acc: 0.6584\n",
      "Epoch 13/30\n",
      "1362/1362 [==============================] - 105s 77ms/step - loss: 1.6363 - acc: 0.5786 - val_loss: 1.3370 - val_acc: 0.6630\n",
      "Epoch 14/30\n",
      "1362/1362 [==============================] - 103s 75ms/step - loss: 1.5976 - acc: 0.5875 - val_loss: 1.3301 - val_acc: 0.6658\n",
      "Epoch 15/30\n",
      "1362/1362 [==============================] - 103s 75ms/step - loss: 1.5813 - acc: 0.5919 - val_loss: 1.3459 - val_acc: 0.6596\n",
      "Epoch 16/30\n",
      "1362/1362 [==============================] - 103s 76ms/step - loss: 1.5584 - acc: 0.5969 - val_loss: 1.3076 - val_acc: 0.6679\n",
      "Epoch 17/30\n",
      "1362/1362 [==============================] - 103s 76ms/step - loss: 1.5410 - acc: 0.6018 - val_loss: 1.2842 - val_acc: 0.6757\n",
      "Epoch 18/30\n",
      "1362/1362 [==============================] - 103s 76ms/step - loss: 1.5263 - acc: 0.6033 - val_loss: 1.2778 - val_acc: 0.6767\n",
      "Epoch 19/30\n",
      "1362/1362 [==============================] - 103s 76ms/step - loss: 1.5063 - acc: 0.6093 - val_loss: 1.2634 - val_acc: 0.6816\n",
      "Epoch 20/30\n",
      "1362/1362 [==============================] - 103s 76ms/step - loss: 1.4933 - acc: 0.6123 - val_loss: 1.2638 - val_acc: 0.6830\n",
      "Epoch 21/30\n",
      "1362/1362 [==============================] - 103s 76ms/step - loss: 1.4813 - acc: 0.6139 - val_loss: 1.2531 - val_acc: 0.6863\n",
      "Epoch 22/30\n",
      "1362/1362 [==============================] - 103s 76ms/step - loss: 1.4693 - acc: 0.6169 - val_loss: 1.2545 - val_acc: 0.6831\n",
      "Epoch 23/30\n",
      "1362/1362 [==============================] - 103s 76ms/step - loss: 1.4549 - acc: 0.6198 - val_loss: 1.2316 - val_acc: 0.6849\n",
      "Epoch 24/30\n",
      "1362/1362 [==============================] - 104s 77ms/step - loss: 1.4439 - acc: 0.6225 - val_loss: 1.2463 - val_acc: 0.6871\n",
      "Epoch 25/30\n",
      "1362/1362 [==============================] - 103s 76ms/step - loss: 1.4302 - acc: 0.6255 - val_loss: 1.2274 - val_acc: 0.6928\n",
      "Epoch 26/30\n",
      "1362/1362 [==============================] - 103s 76ms/step - loss: 1.4186 - acc: 0.6291 - val_loss: 1.2220 - val_acc: 0.6920\n",
      "Epoch 27/30\n",
      "1362/1362 [==============================] - 957s 703ms/step - loss: 1.4081 - acc: 0.6298 - val_loss: 1.2104 - val_acc: 0.6935\n",
      "Epoch 28/30\n",
      "1362/1362 [==============================] - 117s 86ms/step - loss: 1.4015 - acc: 0.6342 - val_loss: 1.2041 - val_acc: 0.6969\n",
      "Epoch 29/30\n",
      "1362/1362 [==============================] - 118s 86ms/step - loss: 1.3911 - acc: 0.6356 - val_loss: 1.2038 - val_acc: 0.6993\n",
      "Epoch 30/30\n",
      "1362/1362 [==============================] - 114s 84ms/step - loss: 1.3885 - acc: 0.6358 - val_loss: 1.2316 - val_acc: 0.6879\n"
     ]
    }
   ],
   "source": [
    "# finally fitting the data and trining the CNN\n",
    "history = classifier.fit_generator(\n",
    "        epochs=30,\n",
    "        initial_epoch=11,\n",
    "        generator=train_set,\n",
    "        steps_per_epoch=1362,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=152,\n",
    "        use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('model-68.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
